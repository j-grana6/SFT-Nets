\documentclass{article}
\usepackage{amsmath}
\usepackage{color}
\makeatletter
\def\Let@{\def\\{\notag\math@cr}}
\makeatother
\begin{document}

\section{Background-ASCII 1-3}

\subsection{The Observation Operator}

	1) Recall that in general, an observation operator is an arbitrary
	noninvertible projection from the space of sequences (the state-space
	transitions and the times they occur). In other words, in the notation
	of our paper, it is a non-invertible function of $(\vec{\sigma},
	\vec{\tau})$. (In math-speak, if we take our observation operator to be
	deterministic, the combination of our observation operator with the
	SFT net is a "unifilar hidden markov process model").  \textcolor{red}{In
	normal-person-speak, we are attempting to find the model that descirbes
	the transmission of messages among nodes.  We know that what we
	observed (the message times) was generated  by applying the observation
	operator to a more complete model.  In other words, the observation 
        operator hides from us some variables of the underlying model.  
        Furthermore, this observation operator is not invertible so we can't 
        just apply it to what we observed as an attempt to get the underlying 
        model.}

\subsection{Likelihood issues}
	\textcolor{red}{In general, one way to pick the best model is to use 
          maximum likelihood} However our likelihood function gives the 
        likelihood of the sequence of fully-specified state-space variables 
        (see Eq. 17 in our paper). \textcolor{red}{In other words, our likelihood
        is a function of some ``stuff'' that the observation operator hides from 
        us.}

	So to calculate the likelihood of an observation (whatever it is
	conditioned on), we must integrate the expression in Eq. 17 over the
	degrees of freedom that the observation operator projects out. In
	general, a horrible problem.  \textcolor{red}{In our case, this translates
	into integrating over the infection times.} 

\subsection{Our Special Scenario}	
        However the scenario that Brian constructed is special ...

	2) In this scenario, what the observation operator gives is the
	time-stamps at which nodes emit messages. All other information -
	states of nodes at all times, and contents of messages at all times -
	is projected out.

	Moreover, we know what the (stationary) Poisson rate of such emissions
	would be from any node $v$ if $v$ were infected, and what the rate would
	be if $v$ were not infected. So we can write down the likelihood of any
	sequence of emissions generated by $v$ if $v$ were infected, and the
	likelihood if $v$ were not.

	3) We also make the assumption that once a node gets infected, it
	stays infected.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Likelihood-ASCII 4-8}
\subsection{If we knew the infection times...}	
    .
	4) Combining 2 and 3  we can write down in closed form the likelihood
        of a sequence of (time-stamps of) emissions from an arbitrary node $v$ 
        across all time, given that  $v$ is uninfected up to $z_{v}$, when it 
        gets infected. \textcolor{red}{By following the same notation in the 
        paper, we express this likelihood as}
        
        \begin{align}
        P(data | z) = \prod_{v\in V}\frac{e^{-\lambda_{v1}z_v}(\lambda_{v1}z_v)^{k_{v1}}}{k_{v1}!}\times 
        \frac{e^{-(\lambda_{v2})(T-z_v)}(\lambda_{v2})(T-z_v)^{k_{v2}}}{k_{v2}!}
        \end{align}
        where $k_{v1}$ is the number of messages emitted from node $v$ before 
        $z_v$, $k_{v2}$ is the number of messages emitted from node $v$ between 
        $z_v$ and $T$, $\lambda_{v1}$ is  homogenous poisson transmission rate for
        node $v$ when it is uninfected and $\lambda_{v2}$ is the  homogenous 
        poisson transmission rate for node $v$ when it is infected.  
 
	Note that this is conditioning on *part* of what it hidden in the
	output of the observation operator, but not everything.  Formally, to
	write down this likelihood we are actually integrating over the values
	of the other hidden variables concerning the messages from $v$ that we
	cannot observe, namely the specifications of whether those messages
	contain malware or not. But for us that integration is trivial. 
	\textcolor{red}{That said, we are actually only integrating over the 
         infection times.}
\subsection{The problem}
	
        5) However the likelihood that we want to calculate is different than 
        equation 1 \textcolor{red}{because the above assumes the infection times 
        are pre-specified.}  For example, in the simplest scenarios we might want
	to test, we would want the likelihood of our entire observation
	sequence either conditioned on the premise that one particular node
	$v'$ is infected at t = 0 \textcolor{red}{corresponding to attacker 
        existence}, or that no nodes are ever infected \textcolor{red}
        {corresponding to no attacker}. Note that in this likelihood we do NOT 
        specify the times of infection for the other nodes for the case that 
        $v'$ is infected at t = 0. In fact, we don't even specify $m$, the number
        of nodes that get infected by time $T$.


	However, we can use equation (1) as part of the  likelihood. To see how, 
        note that if we knew the infection times for all nodes $v$ in the net 
        that get infected,  $z_{v}$,  we would be done.  In other words, in an 
        N-node SFT net, where we can have between 1 and N nodes get infected in 
        the time interval [0, T], it suffices to specify a point z in the union 
        of spaces $\cup_{1 \le M \le N} R^M$ to fix the likelihood of our data.
        Alas, we do not know that vector z.


	6) Therefore to calculate  $P(data  | \text{net infected at } t = 0)$, 
        we need to do an integral, integrating out the vector $z$. We can 
        decompose this integral as follows:

\begin{equation}
\int dz P(d, z | \text{net infected at } t = 0) = \\
\int dz P(d | z, \text{net infected at } t = 0) P(z | \text{net infected at } t=0)
\label{main}
\end{equation}

	  \textcolor{red}{Again, the first term on the RHS is just equation 1 and 
          is trivial to compute.} What to do about the second?

\subsection{Calculating P(z)}
        
        7) To evaluate the second term in the RHS integrand, note that $z$ fixes
	the sequence of successive node infections. Write that sequence as
	$v(1), v(2), \ldots, v(m)$, so that $v(n)$ specifies what node was the 
        $n^{th}$ to be infected, where we are assuming that $v(1)$ is infected 
        at $t = 0$ (so $z_{v(1)} = 0$), but that no other node is infected then, 
        i.e., for all  $i > 1$, $z_{v(i)} > 0$.

	So with our new notation we can write

\begin{equation}
P(z | \text{net infected at } t = 0) = P(\{z_{v(i)}\}, \{v(i)\} | v(1), z_{v(1)} = 0)
\label{split}
\end{equation}
	
        where curly brackets indicate a set. 

	Note that with this new notation, the  $\int dz$ in equation ~\eqref{main} 
        becomes $ \sum_{\{v(i)\}} \int dz_{\{v(i)\}}$.  i.e. the RHS of ~\eqref{main} 
        becomes

\begin{align}
\sum_{v(i)} \int dz_{v(i)} & P(d | 
\{v(i)\}, \{z_{v(i)}\}, \text{net infected at} t  = 0)    \times \\
& P(\{v(i)\}, \{z_{v(i)}\} | \text{net infected at} t=0)
\end{align}

        Note that the sum over $\{v(i)\}$ includes all subsets of the set of $N$
        nodes that form a directed acyclic path over the network topology,
        including those subsets that do not involve all $N$ nodes. But it
        includes no other subsets.

	Concentrate on any particular value of $\{v(i)\}$ and $\{z_{\{v(i)\}}\}$ 
        occuring inside this sum-integral. For that value we can expand the RHS of 
        equation ~\eqref{split} as a product of N conditional distributions,

\begin{align}
& P(v(2), z_{v(2)} |  v(1), z_{v(1)} = 0)    \times  \\
& P(v(3), z_{v(3)} |  v(2), z_{v(2)}, v(1), z_{v(1)} = 0) \times  \ldots  \times \\
& P(\text{no nodes infected in the interval between } z_v(M) \\
&\text{ and the end of the window}  |  \{v(i) : 1 \le i \le M\}, z_{v(i) : 1 \le i \le M})
\end{align}

	Next, use the network topology to figure out the set of edges exiting
	$v(1)$ and write it as $C(1)$. Also define $\lambda(i,j)$ as the Poisson rate
	constant for the composite process of a non-infection message goes
	from infected node $v(i)$ to a non-infected node $v(j)$, or an infection
	message going from an infected node $v(i)$ to a non-infected node $v(j)$
	and $v(j)$ making a transition to being infected when that message
	arrives.  Also define $\lambda(1)$ as $\sum_{j \in C(1)} \lambda(1,j)$,
	i.e., the sum of the rate constants over all edges exiting $v(1)$. Then

\begin{equation}
P(v(2), z_{v(2)} | v(1), z_{v(1)} = 0)  =
\lambda(1) e^{- \lambda(1) (z_{\{v(2)\}} - z_{\{v(1)\}})} 
\times \frac{\lambda(1,2)}{\lambda(1)}
\end{equation}

        as in the Gillespie algorithm -- the
	expression on the RHS equals the probability that the first transition
	among all the nodes that are connected to $v(1)$ occurs at the time
	$z_{v(2)}$, times the probability that it is node $v(2)$ that makes that
	transition). 
        
        As an aside, note that by decomposing the conditional distribution as
        in Eq. 5, we are implicitly re-expressing that distribution with a
        different set of random variables than $(v(i), z_{v(i)}): z_{v(i)}$ is
        replaced by a an M-dimensional vector $(z_1, z_2, ..., z_M)$ that gives
        the times of the first, second, etc. infections, \emph{whichever nodes
        those infections happen to.} (The other component of the pair, the
        vector {v(i)}, is unchanged.) However in what's written below, we
        still use the original set of random variables.

        So after cancellation, we have
	
\begin{equation}
P(v(2), z_{v(2)} | v(1), z_{v(1)} = 0) =
\lambda(1, 2) e^{-|C(1)| \lambda \cdot (z_{\{v(2)\}} - z_{\{v(1))\}}}
\label{orig5}
\end{equation}

	where $\lambda$ is the sum of the (homogenous) background traffic rate
	and infection message traffic rate. 

	Note that $\lambda(1, 2) = 0$ if there is no edge going from $v(1)$ to
	$v(2)$. If it were not for this fact, our formula for the conditional
	distribution $P(v(2), z_{v(2)} | v(1), z_{v(1)} = 0)$ would not be
	normalized.

	Similarly, define $C(2)$ as the set of edges exiting either $v(1)$ or
	$v(2)$, and define $\lambda(2) = \sum_{j \in C(2)} \lambda(2,j)$, i.e., the
	sum of the rate constants over all edges exiting $v(2)$. (I'm pretty
	sure that the possibility of a node being connected to both $v(2)$ and
	$v(1)$ doesn't change the fact that this is the correct sum.)  Then use
	our assumption of homogenous (infected node) rate constants to write

\begin{equation}
P(v(3), z_{v(3)} | v(2), z_{v(2)}, v(1), z_{v(1)} = 0)  =  
K(3) \lambda e^{\lambda(2) (z_{\{v(3)\}} - z_{\{v(2))\}}} 
\end{equation}

	where $K(3)$ equals $1$ or $2$, depending on whether under the network
	topology one or both of $v(1)$ and $v(2)$ are connected to $v(3)$, and
	$\lambda$ is the homogenous rate constant.

	We can keep iterating to evaluate the full term on the RHS of equation 
        ~\eqref{split}, up to the last one, giving the probability of no more 
        infections. To evaluate that last term, define $\lambda(M)$ as the sum of 
        all rate constants for the $M$ nodes $v(1), v(2)$, ... Then as in the 
        derivation of equation ~\eqref{orig5}, I then think that

\begin{align}
P(\text{no nodes infected in the interval between } \\ 
z_v(M) \text{ and the end of the window}  |   
\{v(i) : 1 \le i \le M\}, z_{v(i) : 1 \le i \le  M}) \\
=\\
1 - P(\text{some node is infected in the interval between } \\
z_v(M) \text{ and the end of the window}  |  
\{v(i) : 1 \le i \le M \}, z_{v(i) : 1 \le i \le  M}) = \\
1 - \lambda(M) \exp{\lambda(M) (T - z_{v(M)})}
\end{align}
        where T is the time that the observation window ends.

        At this point we have all the terms whose product gives us the
        conditional distribution we need, and we can use the result to write
        down the summand-integrand in Eq. 1.


	8) Note that only a tiny fraction of the points in $R^{N}$ are physically
	possible. E.g., we can't have a node $v$ get infected at $t$, and then a
	node $v"$ get infected at $t" > t$, and no other nodes ever get infected,
	if due to the network topology the only way v" can get infected is
	from $v$ via a bottleneck node $v'$ lying between $v$ and $v"$. This will be
	reflected in the likelihood function - all disallowed points in $R^{N}$
	will be have likelihood zero, and furthermore, the likelihood function
	will be properly normalized to account for the contorted shape of the
	set of allowed points.

\section{MCMC Methods-ASCII 9-11 and beyond}

        9) Unfortunately, due to the contorted shape of the subset of
        $R^N$ of $z$'s that are actually allowed (given the network topology)
        discussed above, I don't think we can do the sum-integral to give our
        likelihood in closed form. In fact, even if we fix $\{v(i)\}$, I don't
        think we can do the associated integral in closed form. For the same
        reason, simple sampling MC with a uniform distribution over $[0, T]^m$
        (where m is the number of nodes that get infected in $[0, T]$, specified
        by $\{v(i)\}$) may be quite inefficient.

        As an aside, recall the variable transformation discussed just below
        Eq. 5. If we were to make that transformation, then the "contorted
        shape of the subset of $R^M$ of $z$'s that are actually allowed (given the
        network topology)" is replaced by the subset of $R^M$ in which 
        $z_1 \le z_2  ...  \le z_M$ This is a vastly simpler object, one that 
        is *independent of network topology*.

        In fact, it may allow us to do our calculations much more simply. For
        example, now, for every vector $\{v(i)\}$ in our outer sum over DAGs, the 
        integrand (in the new set of variables) is never zero for any of the
        $z$'s in the volume of integration $z_1 \le z_2 \le ... \le z_M.$ So even
        something like importance sampling MC, rather than MCMC, should be
        possible. 

        This leaves us with 4 ways to estimate the integral

\subsection{Metropolis Hastings over $[0, \infty]^N$}

The flow is as follows:
\begin{itemize}
\item Create a set $V$ that contains all allowable node infection orderings of 
size $N$.
\item Initiate $\{v_0(i)\}$
\item Initiate an allowable $\{z_{v(i)_0}\}$.
\item Define $z_0 = \{z_{v(i)_0}\} \cap \{v_0(i)\}$ 
\begin{itemize}
\item for sample in 1:number of mcmc samples
\item if $\alpha$ $<$ $U(0,1)$ : $\{v_1(i)\} = \{v_0(i)\}$
\item else : Draw a new ordering, $\{v_1(i)\}$ from $V$
\item Sample $\{z_{v(i)_1}\} = \{z_{v(i)_0} + \mathcal{N}_i(0, \sigma)\}$
\item Define $z_1 = \{z_{v(i)_1}\} \cap \{v_1(i)\}$ 
\item If $\frac{P(z_1 | \text{net infected})}{P(z_0 | \text{net infected})} > \mathbf{U}(0,1)$
\begin{itemize}
\item $z_0 =z_1$
\item $v_0 = v_1$
\end{itemize}
\item else: $z_0, v_0$ don't change.
\item Record $z_0$, $v_0$ and $P(D | \{z_0(i)\}, \text{net infected} )$
\end{itemize}
\item The value of the integral is the average over all of the $P(D | \{z(i)\}, \text{net infected} )$
\end{itemize}

In fact, we do not have to draw node orderings and infection times separately.  Instead, we can just draw $z$ and if the node ordering is not permitted by the topology, we assign it probability 0 and re-sample.  

\subsection{Importance Sampling over $[0, \infty]^N$}

The importance sampling over $[0, \infty]^N$ will start similarly to the Metropolis-Hastings by sampling infection order.

A quick review on importance sampling.  Suppose we want to approximate
\begin{align}
\int dx f(x)p(x)
\end{align}

If we can sample from $p(x)$ we can just sample $X_1. X_2 ...X_N$ from $p$ and compute $\frac{1}{N}\sum_{i=1}^Nf(X_i)$.
However, if we cannot sample from $p(x)$ but can sample from some other distribution $q(x)$, we can sample $X'_1, X'_2 ...X'_N$ from 
$q(x)$ and compute $\frac{1}{N}\sum_{i=1}^Nw(X'_i)$ where $w(X'_i) = \frac{f(X'_i)p(X'_i)}{q(X'_i)}$.  

In our case, the importance sampling algorithm will be as follows:


\begin{itemize}
\item Create a set $V$ that contains all allowable node infection orderings
\item Initiate an infection order
\item for $\mathbf{samp}$ in 1: imp samps
\begin{itemize}
\item if $\alpha$ $<$ $U(0,1)$ : keep the same infection order
\item else : Draw a new infection order
\item Draw $z_{v(j)}$ (the infection time of the $j$th node to be infected) recursively
as $z_{v(j)} = \sum_{i=1}^{j-1}z_{v(i)} + \mathbf{EXP}(\sum_{i=1}^{j-1}\lambda^{'}_{i,j})$ 
where $\lambda^{'}_{i,j}$ is the (possibly 0) rate of malicious message transmission from $i$ to $j$,  and $\mathbf{EXP}(y)$ is 
an exponential random variable with rate parameter $y$
\item Given a draw of $z$, we can compute $q(z)$ as $\prod_{v(j)\in V}(\sum_{i=1}^{j-1}\lambda^{'}_{i,j})\exp^{-((\sum_{i=1}^{j-1}\lambda^{'}_{i,j})\Delta z_v(j)}$
where $\Delta z_{v(j)} = z_{v(j)} - z_{v(j-1)}$.
\item Record $X_{\mathbf{samp}} = \frac{P(data |z, \text{infected})P(z|\text{infected})}{q(z)}$
\end{itemize}
\item The integral approximation is then $\frac{1}{\text{imp samps}}\sum_{i=1}^{imp samps}X_i$
\end{itemize}

\subsection{Metropolis Hastings Over  $[0, T]$}
        This method is a bit trickier and involves summing over DAGs.  
        As an example, consider the sum-integral over all possible $\{v(i)\}$ and
        associated $R^M$ vectors $z_{v(i)}$ giving our likelihood:
\begin{equation}
\sum_{v(i)} \int dz_{v(i)} P(d | \{v(i)\}, z_{v(i)}, \text{ net infected at t } = 0)  P(\{v(i)\}, z_{v(i)} | \text{ net infected at } t=0)
\label{sumdags}
\end{equation}

        (Note that depending on how many nodes get infected, as specified by
        $\{v(i)\}$, the dimension of $z_{v(i)}$ ranges from 0 to N - 1.).  
        Also remember that to compute the 2nd term on the right hand side of
        equation ~\eqref{sumdags}, we need to compute the probability of nodes
        $i >M$ not getting infected by time $T$.

        To approximate this sum-integral, say we choose the target
        distribution of the MCMC to be 
        $P(\{v(i)\}, z_{v(i)} | \text{net infected } t=0).$
        So we are interested in averaging 
        $P(d | \{v(i)\}, z_{v(i)}, \text{net infectedat } t = 0)$
        over all pairs $(\{v(i)\}, z_{v(i)})$ generated (i.e., kept) in
        the MCMC that has as its target distribution the conditional
        distribution $P(\{v(i)\}, z_{v(i)} | \text{net infected } t=0)$.

        Then we could have the proposal distribution be the following:

        Given a current vector $\{v(i)\}, \{z_v(i)\}$, with some fixed 
        probability alpha, do the following:

        i) leave {v(i)} unchanged, and then generate a new set of values
        $\{z'_v(i)\}$ by the following procedure:
        Uniformly randomly sample $[0, T]$ a total of $M$ times. Order
        those $M$ values from the lowest to the highest. These are the new
        values of the elements in the set $\{z'_v(i)\}$, ordered in order of
        increasing $i$.

        ii) Form a new directed acyclic path through the network topology by
        starting at $v(1)$, randomly choosing one of its outgoing edges to get
        $v(2)$, with fixed probability gamma stopping, and if we don't stop,
        randomly choose from  the set of outgoing edges from $v(2)$ that do
        not lead to $v(1)$ (unless that set is empty, in which case we stop).

        Note that this sampling distribution is not symmetric over all pairs
        $(\{v(i)\}, z_{v(i)})$, so we must use full Metropolis-Hastings.

        To be precise, after forming a sample of this proposal distribution,
        we would keep / reject the associated pair $((\{v(i)\}, z_{v(i)})$
        according to the associated value of 
        $P(\{v(i)\}, z_{v(i)} | \text{net infected } t=0)$ 
        (a value given by the calculation  in point (7) above) combined with an 
        explicit calculation of what the probability of generating that new sample 
        pair is (under the rule for generating pairs given just above). We would 
        then average the associated  value of the quantity 
        $P(d | \{v(i)\}, z_{v(i)}, \text{net infected at } t = 0)$ over all kept
        pairs.

        ===== Note I *think* that we can evaluate the probability of
        generating a new sample pair from a current one up to an overall
        normalization constant, as required by MH, but haven't fully checked.

        The pseudo code for this above method is as follows, but with one small
        change.  Instead of sampling $\{v(i)\}$ as above, we can just directly sample
        the set of all possible $\{v(i)\}$.  I think this would make the proposal 
        distribution symmetric.  

\begin{itemize}
\item Create a set $V$ that contains all allowable node infection orderings of 
size $M \le N$.
\item Initiate $\{v_0(i)\}$
\item Initiate an allowable $\{z_{v(i)_0}\}$.
\item Define $z_0 = \{z_{v(i)_0}\} \land \{v_0(i)\}$ 
\begin{itemize}
\item for sample in 1:number of mcmc samples
\item if $\alpha$ $<$ $U(0,1)$ : $\{v_1(i)\} = \{v_0(i)\}$
\item else : Draw a new ordering, $\{v_1(i)\}$ from $V$
\item Sample $\{z_{v(i)_1}\} = \{z_{v(i)_0} + \mathcal{N}_i(0, \sigma)\}$ for $i=2 ..M'$
\item Define $z_1 = \{z_{v(i)_1}\} \land \{v_1(i)\}$ 
\item If $\frac{P(z_1 | \text{net infected})}{P(z_0 | \text{net infected})} > \mathbf{U}(0,1)$
\begin{itemize}
\item $z_0 =z_1$
\item $v_0 = v_1$
\end{itemize}
\item else: $z_0, v_0$ don't change.
\item Record $z_0$, $v_0$ and $P(D | \{z_0(i)\}, \text{net infected} )$
\end{itemize}
\item The value of the integral is the average over all of the $P(D | \{z(i)\}, \text{net infected} )$
\end{itemize}

The only difference between this and the Metropolis Hastings over $[0, \infty]$ is that in this case, we are only sampling infection times that are less than $T$ and explicitly computing the probability of the other nodes not getting infected.  

\subsection{Importance Sampling over $[0, T]$ }
This method uses the same idea as the Metropols Hastings over $[0, T]$ (i.e. the summing DAGS method) but instead uses importance sampling.  We also take advantage of being able to explicitly compute the probability of witnessing uninfected nodes.   

The pseudo code is as follows:

\begin{itemize}
\item Create a set $V$ that contains all allowable node infection orderings of 
length $M \le N$
\item Initiate an infection order
\item for $\mathbf{samp}$ in 1: imp samps
\begin{itemize}
\item if $\alpha$ $<$ $U(0,1)$ : keep the same infection order of length $M$
\item else : Draw a new infection order $M$
\item Draw $M$ times from $[0,T]$.  Order them.  These are the infection times
\item Given a draw of $z$, we can compute $q(z)$ as $\frac{1}{T}^M \times$ Probability of selecting the specific $\{v(i)\}$ 
\end{itemize}
\item For each $\{v_i\}$ compute the average of the sampled 
$P(data | z_v{i}, \text{ attacker})P(z | attacker)/q(z)$.
\item The value of the integral is the sum of over $\{v(i)\}$ in the previous step.
\end{itemize}
The issue here is the exact computation of $q(z)$.  How do we compute the probability
of sampling a specific $v\{i\}$ and include that in the importance sampling.  

\end{document}

should we try uniform sampling?
