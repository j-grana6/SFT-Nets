1) Recall that in general, an observation operator is an arbitrary
noninvertible projection from the space of sequences of {state-space
transitions and the times they occur}. In other words, in the notation
of our paper, it is a non-invertible function of (\vec{sigma},
\vec{tau}). (In math-speak, if we take our observation operator to be
deterministic, the combination of our observation operator with the
SFT net is a "unifilar hidden markov process model".)

However our likelihood function gives the likelihood of the sequence
of fully-specified state-space variables (see Eq. 17 in our paper).

So to calculate the likelihood of an observation (whatever it is
conditioned on), we must integrate the expression in Eq. 17 over the
degrees of freedom that the observation operator projects out. In
general, a horrible problem.

However the scenario that Brian constructed is special ...


2) In this scenario, what the observation operator gives is the
time-stamps at which nodes emit messages. All other information -
states of nodes at all times, and contents of messages at all times -
is projected out.

Moreover, we know what the (stationary) Poisson rate of such emissions
would be from any node v if v were infected, and what the rate would
be if v were not infected. So we can write down the likelihood of any
sequence of emissions generated by v if v were infected, and the
likelihood if v were not.


3) We also make the assumption that once a node gets infected, it
stays infected.


4) Combining (2) and (3), we can write down in closed form the
likelihood of:

a sequence of observed (time-stamps of) emissions from
an arbitrary node v across all time,
    given that 
v is uninfected up to time z_v, when it gets infected. 

Note that this is conditioning on *part* of what it hidden in the
output of the observation operator, but not everything.  Formally, to
write down this likelihood we are actually integrating over the values
of the other hidden variables concerning the messages from v that we
cannot observe, namely the specifications of whether those messages
contain malware or not. But for us that integration is trivial.


5) However the likelihood that we want to calculate is different from
 the one in (4). For example, in the simplest scenarios we might want
 to test, we would want the likelihood of our entire observation
 sequence either conditioned on the premise that one particular node
v' is infected at t = 0, or that no nodes are ever infected. Note
 that in this likelihood we do NOT specify the times of infection for
 the other nodes for the case that v' is infected at t = 0. In fact,
 we don't even specify m, the number of nodes that get infected.

To calculate this likelihood we can use (4) though. To see how, note
that if we knew the infection times for all nodes v in the net that
get infected, z_v, we would be done. In other words, in an N-node SFT
net, where we can have between 1 and N nodes get infected in the time
interval [0, T], it suffices to specify a point z in the union of
spaces \cup_{1 \le M \le N} R^M to fix the likelihood of our data.
Alas, we do not know that vector z.


6) Therefore ... to complete the full integration discussed in (1),
i.e., to calculate P(data d | net infected at t = 0), we need to do an
integral, integrating out the vector z. We can decompose this integral
as follows:

1]   \int dz P(data d, z | net infected at t = 0)
             =
       \int dz P(d | z, net infected at t = 0) P(z | net infected at t=0)

As just discussed, we know the first term in the RHS integrand. What
to do about the second?


7) To evaluate the second term in the RHS integrand, note that z fixes
the sequence of successive node infections. Write that sequence as
v(1), v(2), ..., v(m), so that v(n) specifies what node was the n'th to be
infected, where we are assuming that v(1) is infected at t = 0 (so
z_v(1) = 0), but that no other node is infected then, i.e., for all 
i > 1, z_v(i) > 0.

So with our new notation we can write

2]  P(z | net infected at t = 0)    =    P({z_v(i)}, {v(i)} | v(1), z_v(1) = 0)

where curly brackets indicate a set.

Note that with this new notation, the \int dz in Eq. 1 becomes
\sum_{v(i)} \int dz_{v(i)}, i.e., the RHS of Eq. 1 becomes

3] \sum_{v(i)} \int dz_{v(i)}
             P(d | {v(i)}, z_{v(i)}, net infected at t  = 0)   x
                              P({v(i)}, z_{v(i)} | net infected at t=0)

Note that the sum over {v(i)} includes all subsets of the set of N
nodes that form a directed acyclic path over the network topology,
including those subsets that do not involve all N nodes. But it
includes no other subsets. 

Concentrate on any particular value of the pair ({v(i)}, {z_{v(i)})
occuring inside this sum-integral. For that value we can expand the
RHS of Eq. 2 as a product of M conditional distributions (where M is
the number of nodes in the list {v(i)}, and so is bounded above by N):

4] P(v(2), z_v(2) |  v(1), z_v(1) = 0)    x  
    P(v(3), z_v(3) |  v(2), z_v(2), v(1), z_v(1) = 0)    x  ....  x
    P(no nodes infected in the interval between z_v(M) and the end of
        the window  |  {v(i) : 1 \le i \le M}, z_{v(i) : 1 \le i \le M})

Next, use the network topology to figure out the set of edges exiting
v(1) and write it as C(1). Also define lambda(i,j) as the Poisson rate
constant for the composite process of {an infection message goes from
an infected node v(i) to a non-infected node v(j), and v(j) makes a
transition to being infected when that message arrives}.  Also define
lambda(1) as sum_{j \in C(1)} lambda(1,j), i.e., the sum of the rate
constants over all edges exiting v(1). Then

5]  P(v(2), z_v(2) |  v(1), z_v(1) = 0)  =   lambda(1) exp{ -lambda(1) (z_{v(2)} - z_{v(1)) } 

                                         x   lambda(1,2)  /  lambda(1)

as in the Gillespie algorithm --- the expression on the RHS equals the
probability that the first transition among all the nodes that are
connected to v(1) occurs at the time z_v(2), times the probability
that it is node v(2) that makes that transition. 

As an aside, note that by decomposing the conditional distribution as
in Eq. 5, we are implicitly re-expressing that distribution with a
different set of random variables than ({v(i), z_{v(i)}): z_{v(i)} is
replaced by a an M-dimensional vector (z_1, z_2, ..., z_M) that gives
the times of the first, second, etc. infections, *whichever nodes
those infections happen to*. (The other component of the pair, the
vector {v(i)}, is unchanged.) However in what's written below, we
still use the original set of random variables.

So after cancellation, P(v(2), z_v(2) | v(1), z_v(1) = 0) is given by

    lambda(1, 2) exp{ -|C(1)| lambda  (z_{v(2)} - z_{v(1)) }

where lambda is the sum of the (homogenous) background traffic rate
and infection message traffic rate. 

Note that lambda(1, 2) = 0 if there is no edge going from v(1) to
v(2). If it were not for this fact, our formula for the conditional
distribution P(v(2), z_v(2) | v(1), z_v(1) = 0) would not be
normalized.

Similarly, define C(2) as the set of edges exiting either v(1) or
v(2), and define lambda(2) = sum__{j \in C(2)} lambda(2,j), i.e., the
sum of the rate constants over all edges exiting v(2). (I'm pretty
sure that the possibility of a node being connected to both v(2) and
v(1) doesn't change the fact that this is the correct sum.)  Then use
our assumption of homogenous (infected node) rate constants to write

P(v(3), z_v(3) | v(2), z_v(2), v(1), z_v(1) = 0)  =  
			K(3) lambda exp{lambda(2) (z_{v(3)} - z_{v(2)) } 

where K(3) equals 1 or 2, depending on whether under the network
topology one or both of v(1) and v(2) are connected to v(3), and
lambda is the homogenous rate constant.

We can keep iterating to evaluate all terms on the RHS of Eq. 2 up to
the last one, giving the probability of no more infections. To
evaluate that last term, define lambda(M) as the sum of all rate
constants for the M nodes v(1), v(2), ... Then as in the derivation of
Eq. 5, I think we can write

P(no nodes infected in the interval between 
  z_v(M) and the end of the window  |  
                        {v(i) : 1 \le i \le M}, z_{v(i) : 1 \le i \le  M})

as 1 - P(some node is infected in the interval between 
             z_v(M) and the end of the window  |  
                        {v(i) : 1 \le i \le M}, z_{v(i) : 1 \le i \le  M})

			=

   1 - lambda(M) exp{lambda(M) (T - z_{v(M)) }

where T is the time that the observation window ends.

At this point we have all the terms whose product gives us the
conditional distribution we need, and we can use the result to write
down the summand-integrand in Eq. 1.



8) Note that only a tiny fraction of the points in R^N are physically
possible. E.g., we can't have a node v get infected at t, and then a
node v" get infected at t" > t, and no other nodes ever get infected,
if due to the network topology the only way v" can get infected is
from v via a bottleneck node v' lying between v and v". This will be
reflected in the likelihood function - all disallowed points in R^N
will be have likelihood zero, and furthermore, the likelihood function
will be properly normalized to account for the contorted shape of the
set of allowed points.



9) Unfortunately though, due to the contorted shape of the subset of
R^M of z's that are actually allowed (given the network topology)
discussed in (8), I don't think we can do the sum-integral to give our
likelihood in closed form. In fact, even if we fix {v(i)}, I don't
think we can do the associated integral in closed form. For the same
reason, simple sampling MC with a uniform distribution over [0, T]^m
(where m is the number of nodes that get infected in [0, T], specified
by {v(i)}) may be quite inefficient.

As an aside, recall the variable transformation discussed just below
Eq. 5. If we were to make that transformation, then the "contorted
shape of the subset of R^M of z's that are actually allowed (given the
network topology)" is replaced by the subset of R^M in which z_1 < z_2
< ... < z_M. This is a vastly simpler object, one that is *independent
of network topology*.

 In fact, it may allow us to do our calculations much more simply. For
 example, now, for every vector {v(i)} in our outer sum over DAGs, the 
integrand (in the new set of variables) is never zero for any of the
z's in the volume of integration z_1 < z_2 < ... < z_M. So even
 something like importance sampling MC, rather than MCMC, should be
 possible. 




10) However I think we can use MCMC to efficiently estimate this total
value of the likelihood under the hypothesis that at t=0 some v_1 is
infected and all other nodes are uninfected. 

As an example, consider the sum-integral over DAG's {v(i)} and
associated R^M vectors z_{v(i)}} giving our likelihood:

   \sum_{v(i)} \int dz_{v(i)} P(d | {v(i)}, z_{v(i)}, net infected at t = 0)  P({v(i)}, z_{v(i)} | net infected t=0)

(Note that depending on how many nodes get infected, as specified by
{v(i)}, the dimension of z_{v(i)} ranges from 0 to N - 1.)

To approximate this sum-integral, say we choose the target
distribution of the MCMC to be P({v(i)}, z_{v(i)} | net infected t=0).
So we are interested in averaging P(d | {v(i)}, z_{v(i)}, net infected
at t = 0) over all pairs ({v(i)}, z_{v(i)}) generated (i.e., kept) in
the MCMC that has as its target distribution the conditional
distribution P({v(i)}, z_{v(i)} | net infected t=0) distribution.

Then we could have the proposal distribution be the following:

Given a current vector {v(i)}, {z_v(i)}, with some fixed probability
alpha, do the following:

  i) leave {v(i)} unchanged, and then generate a new set of values
     {z'_v(i)} by the following procedure:
	Uniformly randomly sample [0, T] a total of M times. Order
     those M values from the lowest to the highest. These are the new
     values of the elements in the set {z'_v(i)}, ordered in order of
     increasing i.

  ii) Form a new directed acyclic path through the network topology by
  starting at v(1), randomly choosing one of its outgoing edges to get
  v(2), with fixed probability gamma stopping, and if we don't stop,
  randomly choose from  the set of outgoing edges from v(2) that do
  not lead to v(1) (unless that set is empty, in which case we stop).

Note that this sampling distribution is not symmetric over all pairs
({v(i)}, z_{v(i)}), so we must use full Metropolis-Hastings.

To be precise, after forming a sample of this proposal distribution,
we would keep / reject the associated pair (({v(i)}, z_{v(i)})
according to the associated value of P({v(i)}, z_{v(i)} | net infected
t=0) (a value given by the calculation in point (7) above) combined
with an explicit calculation of what the probability of generating
that new sample pair is (under the rule for generating pairs given
just above). We would then average the associated value of the
quantity P(d | {v(i)}, z_{v(i)}, net infected at t = 0) over all kept
pairs.

====> Note I *think* that we can evaluate the probability of
generating a new sample pair from a current one up to an overall
normalization constant, as required by MH, but haven't fully checked.




11) Of course, we could also slice and dice the integrand of Eq. 2
other ways.

